{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jenifer Gaitan Final Project",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "# Final Project - _Writing with Algorithms_ \n",
        "### Jenifer Gaitan\n",
        "\n",
        "This is my final project, using the by Interactive textgenrnn Demo w/ GPU lab by Max Woolf as a basis for the recurrent neural network in my work.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86LuZR5sOAe-"
      },
      "source": [
        "## Intentions\n",
        "\n",
        "For this project, I'd like to draw upon my background as a someone who has studied History and Women, Gender, and Sexuality studies. Women authors remain underrepresented in literature. Additionally, in many well-known literary texts women are portrayed in the traditional roles of mothers, wives, and daughters. In essence, their relationship with men is central to their identity. With this in mind, I wanted to analyze Jane Eyre closely as my text because it is one of the top 25 most downloaded texts from the Gutenberg corpus. Furthermore, it is written by a female author in the mid 1800s. Charlotte Brontë, like all of her sisters, used a masculine pen name when publishing her book. This illustrates the conditions under which early women novelists wrote and shared their literature worldwide. Having previously studied the book, I know it depicts many relationships between male and female characters. Jane Eyre is known for centering a woman’s experience in a journey of self-discovery that goes beyond seeking fulfillment and an identity tied to a man. \n",
        "\n",
        "I am inspired by the work of Alison Parrish in her creation of Our Arrival. In reading her computer-generated poetry, I felt that the absence of people mentioned in the text was unique in that it made me ponder it more closely searching for its tie in between the lines of the poem. It also made me question the relationship between humans and nature more closely, such as how I had understood this relationship in previous texts I had read. I will use natural language processing techniques to extract sentences which refer to women from Jane Eyre: An Autobiography by Charlotte Brontë. Literature is largely up to the interpretation of every reader. I’d like to explore how these interpretations can change when the element of computer analysis and algorithms present literature in a new light. \n",
        "\n",
        "As mentioned above, I will use Max Woolf's lab in order to train a model to generate text based on Jane Eyre. I will use this model to generate copious amounts of text about women that I will further analyze. I will use POS tagging and frequency distributions to extract most common information, such as adjectives and verbs, to understand the language that is used in text about women. My hope is that this project will further highlight the impact of early women authors and allow the reader to explore the role of gender in this 19th century novel and in any text they read going forward. I am a firm believer that a creator’s identity and lived experiences affects their writing or other creative endeavors. This is also why I believe that it is important to study how women write about women as it often contrasts how men write about women. Using a recurrent neural network is a new tool for studying literature but also one way to see how even modern technologies are complicit in gender biases. I also hope that projects such as this one can help to create a bridge between the humanities and technology which in my undergraduate experience have had a deep divide. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5O6oI4RPHP7"
      },
      "source": [
        "The cells below set up the code dependencies for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbs57FeUybgL"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_"
      },
      "source": [
        "!pip install -q textgenrnn\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "from nltk import tokenize, word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.book import *\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "Instructions from Woolf:\n",
        "\n",
        "Set the textgenrnn model configuration here: the default parameters here give good results for most workflows. (see the [demo notebook](https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb) for more information about these parameters)\n",
        "\n",
        "If you are using an input file where documents are line-delimited, make sure to set `line_delimited` to `True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR"
      },
      "source": [
        "model_cfg = {\n",
        "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 3,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 30,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 20,   # set higher to train the model for longer\n",
        "    'gen_epochs': 5,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "\n",
        "Upload **any text file** and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"Jane_Eyre.txt\"\n",
        "model_name = 'colaboratory'   # change to set file name of resulting trained models/texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "The cells below being the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf"
      },
      "source": [
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file_name,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=1024,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=100,\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX"
      },
      "source": [
        "# this temperature schedule cycles between 1 very unexpected token, 1 unexpected token, 2 expected tokens, repeat.\n",
        "# changing the temperature schedule can result in wildly different output!\n",
        "temperature = [1.0, 0.5, 0.2, 0.2]   \n",
        "prefix = None   # if you want each generated text to start with a given seed text\n",
        "\n",
        "if train_cfg['line_delimited']:\n",
        "  n = 1000\n",
        "  max_gen_length = 60 if model_cfg['word_level'] else 300\n",
        "else:\n",
        "  n = 1\n",
        "  max_gen_length = 2000 if model_cfg['word_level'] else 10000\n",
        "  \n",
        "timestring = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "gen_file = '{}_gentext_{}.txt'.format(model_name, timestring)\n",
        "\n",
        "textgen.generate_to_file(gen_file,\n",
        "                         temperature=temperature,\n",
        "                         prefix=prefix,\n",
        "                         n=n,\n",
        "                         max_gen_length=max_gen_length)\n",
        "files.download(gen_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esl3cZ_IS2v0"
      },
      "source": [
        "The code above downloads a file containing all of the generated text stored in generated_poems.txt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikabhM4lSP-D"
      },
      "source": [
        "text_sents = open(\"generated_poems.txt\").readlines()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra3Fl4CNSbLR"
      },
      "source": [
        "# Here I am removing the lines breaks, (\\n)\n",
        "\n",
        "text_sents = [sent.lower().replace(\"\\n\", \"\") for sent in text_sents if sent != \"\\n\"]  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fblLZjROXBOM"
      },
      "source": [
        "Below I'll be turning the list above into a string in order to tokenize then POS tag it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG5O61l1SdLr"
      },
      "source": [
        "female_sents_string = ' '.join(text_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaHYSXiYXWgI"
      },
      "source": [
        "words = female_sents_string.split()\n",
        "# The code below removes stop words (I, me, its) etc. which are not useful when analyzing the text\n",
        "words = [word for word in words if word not in stopwords.words('english')]\n",
        "\n",
        "fdist_words = FreqDist(words)\n",
        "fdist_words.most_common(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAUcSzZ_U7zV"
      },
      "source": [
        "female_tokenized_string = tokenize.word_tokenize(female_sents_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFknCFAaWOyr"
      },
      "source": [
        "pos_tagged_female = pos_tag(female_tokenized_string) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVLCjex7gIuy"
      },
      "source": [
        "import nltk, re, pprint\n",
        "from nltk import corpus, sent_tokenize, pos_tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkmcMV7FU8UZ"
      },
      "source": [
        "# These are lists of names that have been categorized as female in the gutenberg corpus which will be made lowercase\n",
        "\n",
        "female_names = corpus.names.words('female.txt')\n",
        "female_names = [name.lower() for name in female_names]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg1CvM66gWwE"
      },
      "source": [
        "# This is how I will determine if a sentence is about a woman\n",
        "\n",
        "woman_identifiers = ['she', 'her', 'hers', 'mrs', 'miss','missus'] + female_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgaXs20XgW-r"
      },
      "source": [
        "# This looks for any identifiers being present in the sentences, and prints the sentences that have mention women.\n",
        "\n",
        "female_sents = []\n",
        "\n",
        "for sent in text_sents:\n",
        "    if any(ident in sent.split() for ident in woman_identifiers):\n",
        "        female_sents.append(sent)\n",
        "\n",
        "# Below all the words in the sentences about women are being POS tagged, with the first example being printed\n",
        "\n",
        "female_text = \" \".join(female_sents)\n",
        "female_text_tags = pos_tag(tokenize.word_tokenize(female_text))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZIdodyFg0kq"
      },
      "source": [
        "# Here I'll be looking for the eight most common tags in female sentences\n",
        "\n",
        "tag_female = nltk.FreqDist(tag for (word, tag) in female_text_tags)\n",
        "tag_female.most_common()[:8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj-szse7jTtz"
      },
      "source": [
        "# This is a list of the most common comparative adjectives (JJR) and superlative adjectives (JJS) in the female sentences\n",
        "\n",
        "female_pos_tagged_jj = [token_tag_pair[0] for token_tag_pair in female_text_tags if token_tag_pair[1].startswith(\"JJR\") or token_tag_pair[1].startswith(\"JJS\") ]\n",
        "\n",
        "fdist_jj = FreqDist(female_pos_tagged_jj)\n",
        "print(fdist_jj)\n",
        "fdist_jj.most_common(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41H-bgzzlTOL"
      },
      "source": [
        "# This is a list of the most common present participle verbs (VBG)\n",
        "\n",
        "female_pos_tagged_vb = [token_tag_pair[0] for token_tag_pair in female_text_tags if token_tag_pair[1].startswith(\"VBG\")]\n",
        "\n",
        "fdist_vb = FreqDist(female_pos_tagged_vb)\n",
        "print(fdist_vb)\n",
        "fdist_vb.most_common(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T7ps8c9kSMZ"
      },
      "source": [
        "In looking at the adjectives and verbs used in the same sentences about women, we can make conclusions about the context in which they are written about. Women are described as as \"sweet\" but also \"worst\" and common verbs give insight into the lives of characters of Jane Eyre, travel (\"going\", \"parting\") and their activities \"looking\" \"talking\" \"sitting\" \"writing\"), etc. This model can be replicated to extract many additional types of information from the sentences."
      ]
    }
  ]
}